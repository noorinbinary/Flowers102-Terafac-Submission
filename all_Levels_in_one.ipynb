{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Level 1\n"
      ],
      "metadata": {
        "id": "67OlaWoOlXlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29j3ke5JGt3g"
      },
      "outputs": [],
      "source": [
        "# Important Pre-requisites\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Due to some Hugging Face API Rate limits we did the installation od dataset locally (int the next block in detailed)\n",
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!wget -q http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\n"
      ],
      "metadata": {
        "id": "t9bB3YQVTvaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\n",
        "!tar -xzf 102flowers.tgz\n",
        "!ls jpg | head\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ePkgrJ-vVxVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "\n",
        "# load labels from Oxford .mat file\n",
        "mat = scipy.io.loadmat(\"imagelabels.mat\")\n",
        "labels = mat[\"labels\"].squeeze() - 1   # convert from 1–102 to 0–101\n",
        "\n",
        "print(\"Total labels:\", len(labels))\n",
        "print(\"Unique classes:\", len(set(labels)))\n",
        "\n",
        "# load image filenames\n",
        "img_dir = \"jpg\"\n",
        "img_files = sorted(os.listdir(img_dir))\n",
        "\n",
        "print(\"Total images:\", len(img_files))\n",
        "\n",
        "# checkpoint to make sure we are going well\n",
        "assert len(img_files) == len(labels), \"Images and labels count mismatch\"\n",
        "print(\"Image-label alignment OK\")\n"
      ],
      "metadata": {
        "id": "t_LEYat2WW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "idx = np.arange(len(img_files))\n",
        "\n",
        "# first split: 80% train, 20% temp\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    idx,\n",
        "    test_size=0.2,\n",
        "    stratify=labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "temp_labels = labels[temp_idx]\n",
        "\n",
        "# second split: 10% val, 10% test\n",
        "val_idx, test_idx = train_test_split(\n",
        "    temp_idx,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_labels,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_idx))\n",
        "print(\"Val:\", len(val_idx))\n",
        "print(\"Test:\", len(test_idx))\n",
        "\n",
        "# verifying proportions\n",
        "n = len(idx)\n",
        "print(\"Ratios:\",\n",
        "      len(train_idx)/n,\n",
        "      len(val_idx)/n,\n",
        "      len(test_idx)/n)\n",
        "\n"
      ],
      "metadata": {
        "id": "GXQhanYJPWfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop((224, 224), scale=(0.7, 1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    A.CenterCrop(224, 224),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "Eyt84KPPWvIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "\n",
        "class FlowersDataset(Dataset):\n",
        "    def __init__(self, img_files, labels, indices, tfms):\n",
        "        self.img_files = img_files\n",
        "        self.labels = labels\n",
        "        self.indices = indices\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.indices[i]\n",
        "        img_path = os.path.join(\"jpg\", self.img_files[idx])\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        y = int(self.labels[idx])\n",
        "\n",
        "        out = self.tfms(image=img)\n",
        "        x = out[\"image\"]\n",
        "\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "cZIrQvUWXQhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = FlowersDataset(img_files, labels, train_idx, train_tfms)\n",
        "val_ds   = FlowersDataset(img_files, labels, val_idx, val_tfms)\n",
        "test_ds  = FlowersDataset(img_files, labels, test_idx, val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "eofrolv8XxTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"Batch shape:\", x.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Classes in batch:\", y.unique())\n",
        "\n"
      ],
      "metadata": {
        "id": "wSrac6SlYps7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = timm.create_model(\"resnet50\", pretrained=True, num_classes=102)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
      ],
      "metadata": {
        "id": "jh4mKYyLYqhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(loader, training):\n",
        "    if training:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in tqdm(loader, leave=False):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        if training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(training):\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            if training:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "d3vRbShmZPEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = 0\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    train_loss, train_acc = run_epoch(train_loader, True)\n",
        "    val_loss, val_acc = run_epoch(val_loader, False)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | \"\n",
        "          f\"train acc {train_acc:.4f} | \"\n",
        "          f\"val acc {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val:\n",
        "        best_val = val_acc\n",
        "        torch.save(model.state_dict(), \"best_resnet50.pth\")\n"
      ],
      "metadata": {
        "id": "u0Re-KycZPxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# load best weights\n",
        "model.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        out = model(x)\n",
        "        preds = out.argmax(1)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "test_acc = (all_preds == all_labels).mean()\n",
        "print(f\"TEST ACCURACY: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "4dB7sYDJZVL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion matrix shape:\", cm.shape)\n"
      ],
      "metadata": {
        "id": "WvJsk21FdbAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(cm, cmap=\"viridis\")\n",
        "plt.title(\"Flowers-102 Confusion Matrix (ResNet-50)- Dhruv Pandita\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4_Z-w9sJdfzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Level 2\n"
      ],
      "metadata": {
        "id": "2atqnmzWicFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "train_tfms_l2 = A.Compose([\n",
        "    A.RandomResizedCrop((224, 224), scale=(0.65, 1.0)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ColorJitter(0.25, 0.25, 0.25, 0.1),\n",
        "    A.HueSaturationValue(10, 15, 10, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.CoarseDropout(max_holes=1, max_height=32, max_width=32, p=0.4),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])\n"
      ],
      "metadata": {
        "id": "Om5s4rRiifWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_l2 = FlowersDataset(img_files, labels, train_idx, train_tfms_l2)\n",
        "val_ds_l2   = FlowersDataset(img_files, labels, val_idx, val_tfms)\n",
        "\n",
        "train_loader_l2 = DataLoader(train_ds_l2, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader_l2   = DataLoader(val_ds_l2, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "5aU2DoG5ihJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "criterion_l2 = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "optimizer_l2 = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=3e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(optimizer_l2, T_max=10)\n"
      ],
      "metadata": {
        "id": "YZUqOoqgiwT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_l2 = 0\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    train_loss, train_acc = run_epoch(train_loader_l2, True)\n",
        "    val_loss, val_acc = run_epoch(val_loader_l2, False)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"L2 Epoch {epoch:02d} | train {train_acc:.4f} | val {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_l2:\n",
        "        best_val_l2 = val_acc\n",
        "        torch.save(model.state_dict(), \"best_resnet50_l2.pth\")\n"
      ],
      "metadata": {
        "id": "Zv2uHTiMi0O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"best_resnet50_l2.pth\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        out = model(x)\n",
        "        preds = out.argmax(1)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "test_acc_l2 = (all_preds == all_labels).mean()\n",
        "print(f\"L2 TEST ACCURACY: {test_acc_l2:.4f}\")\n"
      ],
      "metadata": {
        "id": "Hc38_TNxn0v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Level 3\n"
      ],
      "metadata": {
        "id": "-DXCtWwwHcpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = torch.sigmoid(self.conv(x))   # B×1×H×W\n",
        "        return x * attn, attn\n"
      ],
      "metadata": {
        "id": "ktLrIrNkHeac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "class ResNet50WithAttention(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            \"resnet50\", pretrained=True, features_only=True\n",
        "        )\n",
        "        self.attn = SpatialAttention(2048)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)[-1]      # B×2048×H×W\n",
        "        feats, attn = self.attn(feats)\n",
        "        pooled = self.pool(feats).squeeze(-1).squeeze(-1)\n",
        "        out = self.fc(pooled)\n",
        "        return out, attn\n",
        "\n"
      ],
      "metadata": {
        "id": "C1DrqPgLHfC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_l3 = ResNet50WithAttention().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(model_l3.parameters(), lr=3e-4)\n",
        "\n"
      ],
      "metadata": {
        "id": "xfgFeIwfHsK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch_l3(loader, training):\n",
        "    model_l3.train() if training else model_l3.eval()\n",
        "\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        if training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(training):\n",
        "            out, _ = model_l3(x)\n",
        "            loss = criterion(out, y)\n",
        "            if training:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "WV-ehXf0HvGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val = 0\n",
        "\n",
        "for epoch in range(1, 9):\n",
        "    tr_loss, tr_acc = run_epoch_l3(train_loader_l2, True)\n",
        "    val_loss, val_acc = run_epoch_l3(val_loader_l2, False)\n",
        "\n",
        "    print(f\"L3 {epoch} | train {tr_acc:.4f} | val {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val:\n",
        "        best_val = val_acc\n",
        "        torch.save(model_l3.state_dict(), \"resnet50_attention_l3.pth\")\n"
      ],
      "metadata": {
        "id": "NLmELBIqIETk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# load best L3 model\n",
        "model_l3.load_state_dict(torch.load(\"resnet50_attention_l3.pth\"))\n",
        "model_l3.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        out, _ = model_l3(x)\n",
        "        preds = out.argmax(1)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.cpu().numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "test_acc_l3 = (all_preds == all_labels).mean()\n",
        "print(f\"L3 TEST ACCURACY: {test_acc_l3:.4f}\")\n"
      ],
      "metadata": {
        "id": "TfsReZXtIGfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_classes = 102\n",
        "\n",
        "class_correct = np.zeros(num_classes)\n",
        "class_total = np.zeros(num_classes)\n",
        "\n",
        "for p, y in zip(all_preds, all_labels):\n",
        "    class_total[y] += 1\n",
        "    if p == y:\n",
        "        class_correct[y] += 1\n",
        "\n",
        "class_acc = class_correct / class_total\n",
        "\n",
        "# top 10 easiest classes\n",
        "easy = np.argsort(class_acc)[-10:][::-1]\n",
        "\n",
        "# top 10 hardest classes\n",
        "hard = np.argsort(class_acc)[:10]\n",
        "\n",
        "print(\"Easiest classes:\", easy)\n",
        "print(\"Their accuracies:\", class_acc[easy])\n",
        "\n",
        "print(\"Hardest classes:\", hard)\n",
        "print(\"Their accuracies:\", class_acc[hard])\n"
      ],
      "metadata": {
        "id": "6PRedKqKLP5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_vis, y_vis = next(iter(test_loader))\n",
        "x_vis = x_vis.to(device)\n",
        "\n",
        "model_l3.eval()\n",
        "with torch.no_grad():\n",
        "    _, attn = model_l3(x_vis)\n",
        "\n",
        "attn = attn.cpu()\n",
        "\n",
        "# visualize first 5 samples\n",
        "for i in range(5):\n",
        "    img = x_vis[i].cpu().permute(1,2,0).numpy()\n",
        "    heat = attn[i,0].numpy()\n",
        "\n",
        "    plt.figure(figsize=(6,3))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Input\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(heat, cmap=\"hot\")\n",
        "    plt.title(\"Attention map\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "eSal2BFKMAp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storage\n",
        "activations = None\n",
        "gradients = None\n",
        "\n",
        "def save_acts(module, inp, out):\n",
        "    global activations\n",
        "    activations = out\n",
        "\n",
        "def save_grads(module, grad_in, grad_out):\n",
        "    global gradients\n",
        "    gradients = grad_out[0]\n",
        "\n",
        "# hook the last feature block\n",
        "target_layer = model_l3.backbone.feature_info[-1][\"module\"]\n",
        "layer = dict(model_l3.backbone.named_modules())[target_layer]\n",
        "\n",
        "layer.register_forward_hook(save_acts)\n",
        "layer.register_backward_hook(save_grads)\n"
      ],
      "metadata": {
        "id": "ME4pYf_FNjyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_gc, y_gc = next(iter(test_loader))\n",
        "x_gc = x_gc.to(device)\n",
        "y_gc = y_gc.to(device)\n",
        "\n",
        "model_l3.zero_grad()\n",
        "out, _ = model_l3(x_gc)\n",
        "\n",
        "pred = out.argmax(1)\n",
        "score = out[0, pred[0]]\n",
        "score.backward()\n"
      ],
      "metadata": {
        "id": "thF9YR88N4S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "g = gradients[0].cpu().numpy()   # C×H×W\n",
        "a = activations[0].detach().cpu().numpy()\n",
        "\n",
        "\n",
        "weights = g.mean(axis=(1,2))\n",
        "\n",
        "cam = np.zeros(a.shape[1:], dtype=np.float32)\n",
        "for i, w in enumerate(weights):\n",
        "    cam += w * a[i]\n",
        "\n",
        "cam = np.maximum(cam, 0)\n",
        "cam = cam / cam.max()\n",
        "cam = cv2.resize(cam, (224,224))\n"
      ],
      "metadata": {
        "id": "5zTMkQLaPo3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = x_gc[0].cpu().permute(1,2,0).numpy()\n",
        "img = (img - img.min()) / (img.max() - img.min())\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img)\n",
        "plt.title(\"Original\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(img)\n",
        "plt.imshow(cam, cmap=\"jet\", alpha=0.5)\n",
        "plt.title(\"Grad-CAM\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oJVvg40PQKOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Level 4\n"
      ],
      "metadata": {
        "id": "gzHYVaqSm7gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load L1\n",
        "model_l1 = timm.create_model(\"resnet50\", pretrained=False, num_classes=102)\n",
        "model_l1.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
        "model_l1.to(device).eval()\n",
        "\n",
        "# load L2\n",
        "model_l2 = timm.create_model(\"resnet50\", pretrained=False, num_classes=102)\n",
        "model_l2.load_state_dict(torch.load(\"best_resnet50_l2.pth\"))\n",
        "model_l2.to(device).eval()\n",
        "\n",
        "# load L3 (attention)\n",
        "model_l3 = ResNet50WithAttention()\n",
        "model_l3.load_state_dict(torch.load(\"resnet50_attention_l3.pth\"))\n",
        "model_l3.to(device).eval()\n"
      ],
      "metadata": {
        "id": "IChUf60CSiLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "\n",
        "        p1 = F.softmax(model_l1(x), dim=1)\n",
        "        p2 = F.softmax(model_l2(x), dim=1)\n",
        "        p3, _ = model_l3(x)\n",
        "        p3 = F.softmax(p3, dim=1)\n",
        "\n",
        "        p = (p1 + p2 + p3) / 3\n",
        "        preds = p.argmax(1)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y.numpy())\n",
        "\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "ensemble_acc = (all_preds == all_labels).mean()\n",
        "print(f\"ENSEMBLE TEST ACCURACY: {ensemble_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "e1UYkse2m-OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Level 5\n"
      ],
      "metadata": {
        "id": "vCcK4k37phKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student = timm.create_model(\"mobilenetv3_large_100\", pretrained=True, num_classes=102)\n",
        "student = student.to(device)\n"
      ],
      "metadata": {
        "id": "wCEMIaEfnEI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def distill_loss(student_logits, teacher_probs, y, T=4):\n",
        "    soft = F.kl_div(\n",
        "        F.log_softmax(student_logits / T, dim=1),\n",
        "        teacher_probs,\n",
        "        reduction=\"batchmean\"\n",
        "    ) * (T*T)\n",
        "\n",
        "    hard = F.cross_entropy(student_logits, y)\n",
        "    return 0.7 * soft + 0.3 * hard\n"
      ],
      "metadata": {
        "id": "fp3Fk7YGpjw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def teacher_predict(x):\n",
        "    with torch.no_grad():\n",
        "        p1 = F.softmax(model_l1(x), dim=1)\n",
        "        p2 = F.softmax(model_l2(x), dim=1)\n",
        "        p3, _ = model_l3(x)\n",
        "        p3 = F.softmax(p3, dim=1)\n",
        "        return (p1 + p2 + p3) / 3\n"
      ],
      "metadata": {
        "id": "CVbhUmUMqRbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(student.parameters(), lr=3e-4)\n",
        "\n",
        "for epoch in range(6):\n",
        "    student.train()\n",
        "    total, correct = 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            teacher_p = teacher_predict(x)\n",
        "\n",
        "        out = student(x)\n",
        "        loss = distill_loss(out, teacher_p, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    print(f\"KD Epoch {epoch} | Train Acc {correct/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "wPsXJ2wVpoJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_cpu = student.cpu()\n",
        "student_cpu.eval()\n",
        "\n",
        "student_q = torch.quantization.quantize_dynamic(\n",
        "    student_cpu, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")\n"
      ],
      "metadata": {
        "id": "NHEv_0j0ps1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = torch.randn(1,3,224,224)\n",
        "t0 = time.time()\n",
        "for _ in range(100):\n",
        "    student_q(x)\n",
        "print(\"Latency ms:\", (time.time()-t0)/100*1000)\n"
      ],
      "metadata": {
        "id": "7JVRwrRUsJnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_q.eval()\n",
        "correct, total = 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cpu(), y\n",
        "        out = student_q(x)\n",
        "        preds = out.argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(\"STUDENT TEST ACC:\", correct / total)\n"
      ],
      "metadata": {
        "id": "r5redirOsSV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_uncertainty(x):\n",
        "    p = F.softmax(student_q(x), dim=1)\n",
        "    entropy = -(p * p.log()).sum(1)\n",
        "    return p.argmax(1), entropy\n"
      ],
      "metadata": {
        "id": "RcYe3GVhsrW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export TorchScript for deployment\n",
        "example = torch.randn(1,3,224,224)\n",
        "traced = torch.jit.trace(student_q, example)\n",
        "traced.save(\"flower_classifier_int8.pt\")\n",
        "\n",
        "print(\"Saved deployable model: flower_classifier_int8.pt\")\n"
      ],
      "metadata": {
        "id": "viHgr3m1s6zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "esIOeHLytycP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}